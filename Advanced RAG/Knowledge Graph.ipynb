{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Using Knowledge Graph Context and Vector Index</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from llama_index.core import VectorStoreIndex,ServiceContext\n",
    "from llama_index.core import KnowledgeGraphIndex, SimpleDirectoryReader\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.graph_stores.nebula import NebulaGraphStore\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core.graph_stores import SimpleGraphStore\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Setting up Environment</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load variables from the .env file into environment variables\n",
    "dotenv_path = '.env'\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "\n",
    "# Setting up LLM for Llama_index\n",
    "llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "Settings.llm = llm\n",
    "Settings.chunk_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Loading documents from local</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"data\").load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Setup Nebula Graph Store</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "space_name = \"paul_graham_essay\"\n",
    "edge_types, rel_prop_names = [\"relationship\"], [\n",
    "    \"relationship\"\n",
    "] \n",
    "tags = [\"entity\"] \n",
    "\n",
    "graph_store = NebulaGraphStore(\n",
    "    space_name=space_name,\n",
    "    edge_types=edge_types,\n",
    "    rel_prop_names=rel_prop_names,\n",
    "    tags=tags,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Creating index with documents ang Graph store</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pathi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Parsing nodes: 100%|██████████| 2/2 [00:00<00:00, 18.07it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.05it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.37it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.25it/s]\n",
      "Generating embeddings: 100%|██████████| 10/10 [00:00<00:00, 11.44it/s]\n",
      "Generating embeddings: 100%|██████████| 3/3 [00:00<00:00,  4.34it/s]\n",
      "Generating embeddings: 100%|██████████| 14/14 [00:01<00:00, 11.94it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  2.91it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.27it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.22it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.40it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.18it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  2.77it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.27it/s]\n",
      "Generating embeddings: 100%|██████████| 3/3 [00:00<00:00,  4.94it/s]\n",
      "Generating embeddings: 100%|██████████| 4/4 [00:01<00:00,  3.03it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.25it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.34it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  2.52it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.24it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.34it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  2.75it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.25it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.25it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  2.82it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.33it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.30it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.30it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.27it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.38it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.41it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.00it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.45it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.35it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  2.84it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.08it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.26it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.39it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:05<00:00,  2.52s/it]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  2.99it/s]\n",
      "Generating embeddings: 100%|██████████| 3/3 [00:00<00:00,  4.98it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.30it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  2.89it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.32it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.26it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:01<00:00,  1.94it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.36it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.22it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.33it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.55it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.36it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.35it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.29it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.32it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.36it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.31it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.37it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.36it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.48it/s]\n",
      "Generating embeddings: 100%|██████████| 3/3 [00:00<00:00,  5.22it/s]\n",
      "Generating embeddings: 100%|██████████| 3/3 [00:00<00:00,  5.05it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.23it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.26it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.31it/s]\n",
      "Generating embeddings: 100%|██████████| 3/3 [00:00<00:00,  3.71it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.29it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  2.59it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:04<00:00,  2.23s/it]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.32it/s]\n",
      "Generating embeddings: 100%|██████████| 10/10 [00:00<00:00, 11.30it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.43it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.35it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  2.94it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  2.83it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.15it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  2.87it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.28it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.35it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.30it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.53it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.28it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.32it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:01<00:00,  1.15it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  2.89it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.20it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  2.54it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.54it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.36it/s]\n",
      "Processing nodes: 100%|██████████| 87/87 [02:50<00:00,  1.96s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "storage_context = StorageContext.from_defaults(graph_store=graph_store)\n",
    "\n",
    "nebula_index = KnowledgeGraphIndex.from_documents(\n",
    "    documents,\n",
    "    max_triplets_per_chunk=2,\n",
    "    storage_context=storage_context,\n",
    "    show_progress=True,\n",
    "    include_embeddings=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Creating Graph Query Engine and Querying</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cricket is a game that is perceived to be a bat-and-ball game, played in South East England, originated in England, played between two teams, played on modified fields, has historical ties, influenced lexicon, is the subject of works, suggests David Block, is played on a field, regulated by umpires, spread globally with the British Empire, stopped during the Second World War, influenced popular culture, dominated by Don Bradman, began to expand in 1888-89, and has a broad impact.\n"
     ]
    }
   ],
   "source": [
    "graph_query_engine = nebula_index.as_query_engine(response_mode=\"tree_summarize\",include_text=False)\n",
    "\n",
    "response = graph_query_engine.query(\n",
    "    \"What is Cricket?\",\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Creating Vector index from given documents</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pathi\\AppData\\Local\\Temp\\ipykernel_20640\\2192372189.py:2: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context = ServiceContext.from_defaults(llm=llm, chunk_size=1024)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "storage_context = StorageContext.from_defaults()\n",
    "service_context = ServiceContext.from_defaults(llm=llm, chunk_size=1024)\n",
    "vector_index = VectorStoreIndex.from_documents(\n",
    "    documents=documents,\n",
    "    service_context=service_context,\n",
    "    storage_context=storage_context\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Querying with Vector index</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Cricket is a bat-and-ball game played between two teams of eleven players on a field with a 22-yard pitch containing a wicket at each end. The game involves a bowler from the fielding team bowling the ball towards the striker's wicket, with the striker aiming to hit the ball and score runs by exchanging places with the nonstriker. The fielding team aims to dismiss batters to prevent runs from being scored. Cricket has various forms, ranging from Twenty20 to Test matches, and is governed by the International Cricket Council (ICC) with rules maintained by the Marylebone Cricket Club (MCC).\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_query_engine = vector_index.as_query_engine()\n",
    "\n",
    "response1 = vector_query_engine.query(\"What is Cricket?\")\n",
    "response1.response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Comparing query response of Graph and Vector index</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The relationship between cricket and baseball is that they are both bat-and-ball games.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Cricket and baseball are both bat-and-ball sports played between two teams, each with a specific number of players. In cricket, the game is played with eleven players on each team, while in baseball, each team consists of nine players. Both sports involve scoring runs by hitting the ball and running between designated points on the field. Additionally, both sports have a defensive team that aims to prevent the opposing team from scoring runs by getting players out. Despite some differences in rules and gameplay, cricket and baseball share similarities in their fundamental structure and objectives as bat-and-ball games.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = graph_query_engine.query(\n",
    "    \"What is the relationship between cricket and baseball?\",\n",
    ")\n",
    "print(response)\n",
    "\n",
    "response1 = vector_query_engine.query(\"What is the relationship between cricket and baseball?\")\n",
    "response1.response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Giving graph output as context for Vector Index</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The relationship between cricket and baseball is that they are both bat-and-ball games. Both sports involve hitting a ball with a hand-held implement - a bat in this case. While cricket has a solid target structure called the wicket that the batter must defend, baseball has bases that the batter must run to. Additionally, both games have a pitcher (bowler in cricket) who delivers the ball to the batter. The objective in both sports is to score runs by hitting the ball and running between designated points. Despite some differences in rules and gameplay, the fundamental similarity lies in the concept of using a bat to hit a ball in a competitive setting.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the relationship between cricket and baseball?\"\n",
    "response = graph_query_engine.query(\n",
    "    query\n",
    ")\n",
    "ext_query = f\"Context from knowledge graph{response.response}. Query: What is the relationship between baseball and cricket? Note: Use context from knowledge graph and produce the output in elaborate\"\n",
    "response1 = vector_query_engine.query(ext_query)\n",
    "print(response1.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"invoices\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 7/7 [00:00<00:00, 2128.47it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.10it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.07s/it]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  2.69it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  2.82it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  2.89it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.37it/s]\n",
      "Processing nodes: 100%|██████████| 7/7 [00:13<00:00,  1.92s/it]\n"
     ]
    }
   ],
   "source": [
    "storage_context = StorageContext.from_defaults(graph_store=graph_store)\n",
    "\n",
    "nebula_index1 = KnowledgeGraphIndex.from_documents(\n",
    "    documents,\n",
    "    max_triplets_per_chunk=2,\n",
    "    storage_context=storage_context,\n",
    "    show_progress=True,\n",
    "    include_embeddings=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To compare the invoices of all companies provided in the context, you would need to analyze the total amount due on each invoice. This analysis would involve examining the amount owed on each invoice issued by the different companies to determine any variations or similarities in the total amounts due.\n"
     ]
    }
   ],
   "source": [
    "graph_query_engine = nebula_index1.as_query_engine(response_mode=\"tree_summarize\",include_text=False)\n",
    "\n",
    "response = graph_query_engine.query(\n",
    "    \"Compare invoices of all companies given in the context by analizing total amount due\",\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pathi\\AppData\\Local\\Temp\\ipykernel_20640\\1867765008.py:2: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context = ServiceContext.from_defaults(llm=llm, chunk_size=1024)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Smith Enterprises has a total amount due of $2180, while Johnson Ltd. has a total amount due of $1653.6. Therefore, Smith Enterprises has a higher total amount due compared to Johnson Ltd.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "storage_context = StorageContext.from_defaults()\n",
    "service_context = ServiceContext.from_defaults(llm=llm, chunk_size=1024)\n",
    "vector_index1 = VectorStoreIndex.from_documents(\n",
    "    documents=documents,\n",
    "    service_context=service_context,\n",
    "    storage_context=storage_context\n",
    ")\n",
    "vector_query_engine = vector_index1.as_query_engine()\n",
    "\n",
    "response1 = vector_query_engine.query(\"Compare invoices of all companies given in the context by analizing total amount due\")\n",
    "response1.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
